{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10748120,"sourceType":"datasetVersion","datasetId":6665824}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phân lớp","metadata":{}},{"cell_type":"markdown","source":"## Import thư viện","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\nimport os\nimport numpy as np \nfrom sklearn.metrics import confusion_matrix, classification_report \nimport seaborn as sns \nimport matplotlib.pyplot as plt ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:29:15.241541Z","iopub.execute_input":"2025-02-15T10:29:15.241895Z","iopub.status.idle":"2025-02-15T10:29:15.245898Z","shell.execute_reply.started":"2025-02-15T10:29:15.241867Z","shell.execute_reply":"2025-02-15T10:29:15.245152Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Xây dựng Dataset và DataLoader","metadata":{}},{"cell_type":"code","source":"class ChessPiecesDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = sorted(os.listdir(root_dir))\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n        self.samples = []\n        for target_class in self.classes:\n            class_dir = os.path.join(self.root_dir, target_class)\n            for root, _, fnames in sorted(os.walk(class_dir, followlinks=True)):\n                for fname in sorted(fnames):\n                    path = os.path.join(root, fname)\n                    item = path, self.class_to_idx[target_class]\n                    self.samples.append(item)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, target = self.samples[idx]\n        sample = Image.open(path).convert('RGB')\n        if self.transform is not None:\n            sample = self.transform(sample)\n        return sample, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:30:38.899562Z","iopub.execute_input":"2025-02-15T10:30:38.899876Z","iopub.status.idle":"2025-02-15T10:30:38.905484Z","shell.execute_reply.started":"2025-02-15T10:30:38.899854Z","shell.execute_reply":"2025-02-15T10:30:38.904672Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Data augmentation và transforms\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),  \n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n])\n\nval_test_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:30:47.152786Z","iopub.execute_input":"2025-02-15T10:30:47.153069Z","iopub.status.idle":"2025-02-15T10:30:47.157465Z","shell.execute_reply.started":"2025-02-15T10:30:47.153048Z","shell.execute_reply":"2025-02-15T10:30:47.156807Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = ChessPiecesDataset(root_dir='/kaggle/input/chesspieces/ChessPieces_Dataset/train', transform=train_transforms)\nval_dataset = ChessPiecesDataset(root_dir='/kaggle/input/chesspieces/ChessPieces_Dataset/val', transform=val_test_transforms)\ntest_dataset = ChessPiecesDataset(root_dir='/kaggle/input/chesspieces/ChessPieces_Dataset/test', transform=val_test_transforms)\n\n\n# Create DataLoaders\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:31:57.825506Z","iopub.execute_input":"2025-02-15T10:31:57.825849Z","iopub.status.idle":"2025-02-15T10:32:07.351708Z","shell.execute_reply.started":"2025-02-15T10:31:57.825814Z","shell.execute_reply":"2025-02-15T10:32:07.350850Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Chọn và xây dựng mô hình Resnet50","metadata":{}},{"cell_type":"code","source":"# Sử dụng pre-trained ResNet\nmodel = models.resnet50(weights=True)\n\n# Thay đổi lớp fully connected cuối cùng\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 6)  # 6 lớp quân cờ\n\n# Chuyển mô hình sang GPU \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:34:02.767261Z","iopub.execute_input":"2025-02-15T10:34:02.767550Z","iopub.status.idle":"2025-02-15T10:34:03.256006Z","shell.execute_reply.started":"2025-02-15T10:34:02.767527Z","shell.execute_reply":"2025-02-15T10:34:03.255281Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"# Định nghĩa hàm mất mát và optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)  \n\n# Huấn luyện\nnum_epochs = 30  \ntrain_losses = []\nval_losses = []\ntrain_accuracies = []\nval_accuracies = []\n\nfor epoch in range(num_epochs):\n    model.train()  \n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for inputs, labels in train_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()  \n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()  \n        optimizer.step()  \n\n        running_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs.data, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_dataset)\n    train_accuracy = 100 * correct_train / total_train\n    train_losses.append(train_loss)\n    train_accuracies.append(train_accuracy)\n\n  \n    model.eval()  \n    running_loss = 0.0\n    correct_val = 0\n    total_val = 0\n\n    with torch.no_grad(): \n        for inputs, labels in val_loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs.data, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n    val_loss = running_loss / len(val_dataset)\n    val_accuracy = 100 * correct_val / total_val\n    val_losses.append(val_loss)\n    val_accuracies.append(val_accuracy)\n\n\n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T10:38:09.549006Z","iopub.execute_input":"2025-02-15T10:38:09.549293Z","iopub.status.idle":"2025-02-15T10:42:46.231492Z","shell.execute_reply.started":"2025-02-15T10:38:09.549272Z","shell.execute_reply":"2025-02-15T10:42:46.230431Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30, Train Loss: 0.7327, Train Acc: 72.58%, Val Loss: 0.5578, Val Acc: 80.97%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-11bab73311f5>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtotal_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"markdown","source":"## Đánh giá mô hình trên tập test","metadata":{}},{"cell_type":"code","source":"model.eval()  \ncorrect = 0\ntotal = 0\nall_predictions = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        all_predictions.extend(predicted.cpu().numpy())  \n        all_labels.extend(labels.cpu().numpy()) \n\n\nprint(f'Accuracy on the test set: {100 * correct / total:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion matrix \ncm = confusion_matrix(all_labels, all_predictions)\nclass_names = test_dataset.classes \nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification report\nprint(classification_report(all_labels, all_predictions, target_names=class_names))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vẽ loss và accuracy\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracies, label='Train Accuracy')\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}